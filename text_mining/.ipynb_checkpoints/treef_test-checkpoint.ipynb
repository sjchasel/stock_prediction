{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T08:15:32.052480Z",
     "start_time": "2021-05-23T08:15:32.036026Z"
    }
   },
   "outputs": [],
   "source": [
    "from paragraph_feature import *\n",
    "from preprocess import *\n",
    "from sentence_feature import *\n",
    "from word_feature import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T08:15:30.811731Z",
     "start_time": "2021-05-23T08:15:28.786114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    石油石化行业中，4月23日当周北上资金个股净流入主力为恒力石化、东方盛虹、荣盛石化、桐昆股份、华锦股份，其中，恒力石化净流入1.92亿元；当周北上资金个股净流出前三为中国石化、中国石油、恒逸石化。 ???\\r\\r\\r\\n    基础化工行业中，4月23日当周北上资金个股净流入主力为国瓷材料、天赐材料、恩捷股份、玲珑轮胎、华鲁恒升，其中，国瓷材料净流入4.53亿元；北上资金个股净流出前三为万华化学、龙蟒佰利、光威复材。 ???\\r\\r\\r\\n    新材料行业中，4月23日当周北上资金个股净流入主力为南山铝业、中国宝安、中泰化学、云海金属、方大炭素，其中，南山铝业净流入1.4亿元；北上资金个股净流出前三为光威复材、金发科技、彤程新材。 ???\\r\\r\\r\\n    4月23日当周，石油石化行业北上资金测算累计净流出173百万，其中配置型、交易型和托管于内港资机构的资金净流入124、-182、-115百万元；基础化工行业北上资金测算累计净流入1310百万，其中配置型、交易型和托管于内港资机构的资金净流入2763、-1306、-147百万元；新材料行业北上资金测算累计净流入575百万，其中配置型、交易型和托管于内港资机构的资金净流入298、369、-93百万元。 ???\\r\\r\\r\\n    截至2021年4月23日，北上资金持有A股石油石化行业市值229亿，其中配置型、交易型和托管于内港资机构的资金分别持有183、36、10亿元；北上资金持有A股基础化工行业市值897亿，其中配置型、交易型和托管于内港资机构的资金分别持有695、166、37亿元；北上资金持有A股新材料行业市值178亿，其中配置型、交易型和托管于内港资机构的资金分别持有117、44、18亿元。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industry = pd.read_csv(\"C:/Users/12968/Desktop/数据科学实战-stock prediction/industry.csv\", encoding=\"gbk\")\n",
    "sample = list(industry['content'])[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T08:28:26.565276Z",
     "start_time": "2021-05-23T08:28:26.539377Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "from nltk.tree import Tree\n",
    "import re\n",
    "import numpy as np\n",
    "import logging\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from summarize import *\n",
    "\n",
    "\n",
    "PATH = '../词典/'\n",
    "\n",
    "\n",
    "class ParseTree:\n",
    "\n",
    "    def __init__(self, text):\n",
    "        self.text = text  # 传入的文本\n",
    "        # 定义模型\n",
    "        self.nlp = StanfordCoreNLP(r'E:/py/stanford-corenlp-4.2.0', lang='zh', quiet=False, logging_level=logging.DEBUG)\n",
    "        # 分句\n",
    "        self.sentences = self.preprocess()\n",
    "        self.stopwords = []\n",
    "\n",
    "    def load_dicts(self):\n",
    "        stop = PATH + 'stop1205.txt'\n",
    "        self.stopwords = self.dict_load(stop)\n",
    "\n",
    "#     def preprocess(self):\n",
    "#         \"\"\"\n",
    "#         预处理：\n",
    "#         1. 去除换行符、多余的空格、百分号\n",
    "#         2. 分句，存入列表\n",
    "#         :return:返回句子列表\n",
    "#         \"\"\"\n",
    "#         sentences = []\n",
    "#         self.text = re.sub('%', '', re.sub(' ', '', re.sub('\\xa0\\xa0\\xa0\\r\\n', '', self.text)))\n",
    "#         start = 0\n",
    "#         for i in range(len(self.text)):\n",
    "#             if self.text[i] in ['。', '!', '；', '？', '……']:\n",
    "#                 sentences.append(self.text[start:i + 1])\n",
    "#                 start = i + 1\n",
    "#         return sentences\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        把文本处理成摘要句子列表\n",
    "        \"\"\"\n",
    "        return get_sum(self.text)\n",
    "        \n",
    "    def tree(self, sentence):\n",
    "        res = self.nlp.parse(sentence)\n",
    "        # nlp.close()\n",
    "        return res\n",
    "\n",
    "    def sum_of_heights(self):\n",
    "        \"\"\"\n",
    "        计算整篇文本的每句话构成的语法分析树的高度之和\n",
    "        :return: 高度之和\n",
    "        \"\"\"\n",
    "        sumHeights = []\n",
    "        for sentence in self.sentences:\n",
    "            res = self.tree(sentence)  # 语法树，是个字符串\n",
    "            sumHeights.append(len(res.split(\"\\r\\n\")))\n",
    "        return np.sum(sumHeights)\n",
    "\n",
    "    def avg_height(self):\n",
    "        \"\"\"\n",
    "        这篇文章的每句话的语法分析树的平均高度\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.sum_of_heights() / len(self.sentences)\n",
    "\n",
    "    def no_less_than_16(self):\n",
    "        \"\"\"\n",
    "        计算整篇文本的高度不大于16的语法分析树的个数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num = 0\n",
    "        for sentence in self.sentences:\n",
    "            res = self.tree(sentence)\n",
    "            if len(res) >= 16:\n",
    "                num += 1\n",
    "        return num\n",
    "\n",
    "    def no_less_than_16_percent(self):\n",
    "        \"\"\"\n",
    "        高度不低于１６的语法分析树的比例\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.no_less_than_16() / len(self.sentences)\n",
    "\n",
    "    def nodes_sum(self):\n",
    "        \"\"\"\n",
    "        总节点数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        node_sums = []\n",
    "        for sentence in self.sentences:\n",
    "            res = self.nlp.parse(sentence)\n",
    "            result = -1  # 去除root\n",
    "            for i in res:\n",
    "                if i == '(':\n",
    "                    result += 1\n",
    "            node_sums.append(result)\n",
    "        return np.sum(node_sums)\n",
    "\n",
    "    def avg_nodes_sentence(self):\n",
    "        \"\"\"\n",
    "        每句话的平均节点\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.nodes_sum() / len(self.sentences)\n",
    "\n",
    "    def seg_sentence(self, sentence):\n",
    "        \"\"\"\n",
    "        输入字符串，返回分词后的列表\n",
    "        :param sentence:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        jieba.load_userdict('../词典/userdict.txt')\n",
    "        sentence_seged = jieba.cut(sentence.strip())\n",
    "        outstr = ''\n",
    "        for word in sentence_seged:\n",
    "            if word not in self.stopwords:\n",
    "                if word != '\\t':\n",
    "                    outstr += word\n",
    "                    outstr += \" \"\n",
    "        return outstr.split(' ')\n",
    "\n",
    "    def avg_nodes_word(self):\n",
    "        \"\"\"\n",
    "        每个词的平均节点\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 计算有几个词\n",
    "        num = 0\n",
    "        for sentence in self.sentences:\n",
    "            sentence = self.seg_sentence(sentence)\n",
    "            num += len(sentence)\n",
    "        return self.nodes_sum() / num\n",
    "\n",
    "    def np_sum(self):\n",
    "        \"\"\"\n",
    "        计算整篇文章里的名词短语个数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num = 0\n",
    "        for sentence in self.sentences:\n",
    "            res = self.tree(sentence).split(\"\\r\\n\")\n",
    "            for i in res:\n",
    "                if 'NP' in i:\n",
    "                    num += 1\n",
    "        return num\n",
    "\n",
    "    def avg_np(self):\n",
    "        \"\"\"\n",
    "        语法分析树的平均名词短语个数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.np_sum() / len(self.sentences)\n",
    "\n",
    "    def vp_sum(self):\n",
    "        \"\"\"\n",
    "        计算整篇文章里的动词短语个数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num = 0\n",
    "        for sentence in self.sentences:\n",
    "            res = self.tree(sentence).split(\"\\r\\n\")\n",
    "            for i in res:\n",
    "                if 'VP' in i:\n",
    "                    num += 1\n",
    "        return num\n",
    "\n",
    "    def avg_vp(self):\n",
    "        \"\"\"\n",
    "        语法分析树的平均动词短语个数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.vp_sum() / len(self.sentences)\n",
    "\n",
    "    def adjp_sum(self):\n",
    "        \"\"\"\n",
    "        计算整篇文章里的形容词短语个数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num = 0\n",
    "        for sentence in self.sentences:\n",
    "            res = self.tree(sentence).split(\"\\r\\n\")\n",
    "            for i in res:\n",
    "                if 'ADJP' in i:\n",
    "                    num += 1\n",
    "        return num\n",
    "\n",
    "    def avg_adjp(self):\n",
    "        \"\"\"\n",
    "        语法分析树的平均形容词短语个数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.adjp_sum() / len(self.sentences)\n",
    "\n",
    "    def get_res(self):\n",
    "        res = {}\n",
    "        res['sum_height'] = self.sum_of_heights()\n",
    "        res['height_16'] = self.no_less_than_16()\n",
    "        res['sum_node'] = self.nodes_sum()\n",
    "        res['sum_n'] = self.np_sum()\n",
    "        res['sum_v'] = self.vp_sum()\n",
    "        res['sum_adj'] = self.adjp_sum()\n",
    "        res['avg_height'] = self.avg_height()\n",
    "        res['16_ratio'] = self.no_less_than_16_percent()\n",
    "        res['avg_node'] = self.avg_nodes_sentence()\n",
    "        res['word_avg_node'] = self.avg_nodes_word()\n",
    "        res['avg_n'] = self.avg_np()\n",
    "        res['avg_v'] = self.avg_vp()\n",
    "        res['avg_adj'] = self.avg_adjp()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T08:29:36.459184Z",
     "start_time": "2021-05-23T08:28:28.129323Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing native server...\n",
      "INFO:root:java -Xmx4g -cp \"E:\\py\\stanford-corenlp-4.2.0\\*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9006\n",
      "INFO:root:Server shell PID: 10536\n",
      "INFO:root:The server is available.\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9006\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9006 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 40598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sum_height': 65,\n",
       " 'height_16': 1,\n",
       " 'sum_node': 105,\n",
       " 'sum_n': 21,\n",
       " 'sum_v': 18,\n",
       " 'sum_adj': 2,\n",
       " 'avg_height': 65.0,\n",
       " '16_ratio': 1.0,\n",
       " 'avg_node': 105.0,\n",
       " 'word_avg_node': 2.019230769230769,\n",
       " 'avg_n': 21.0,\n",
       " 'avg_v': 18.0,\n",
       " 'avg_adj': 2.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = ParseTree(sample)\n",
    "tree.get_res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T08:20:19.847576Z",
     "start_time": "2021-05-23T08:20:19.792721Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

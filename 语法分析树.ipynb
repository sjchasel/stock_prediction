{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T11:42:34.200506Z",
     "start_time": "2021-04-25T11:42:31.723161Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T11:42:36.992884Z",
     "start_time": "2021-04-25T11:42:35.334388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cate</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>ins</th>\n",
       "      <th>person</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60715ab0a68de4a0c42408aa</td>\n",
       "      <td>公司</td>\n",
       "      <td>事件：    \\r\\n    公司发布2021 年第一季度业绩预增公告。公司2021...</td>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>上海申银万国证券研究所有限公司</td>\n",
       "      <td>张雷/陈明雨/黄华栋</td>\n",
       "      <td>东方电缆(603606)：完善产业布局 海缆及海工业务高速增长</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>60715ab2a68de4a0c42408af</td>\n",
       "      <td>公司</td>\n",
       "      <td>2020 年营收基本与2019 年持平，现金分红比例高达123%2020 年营收约1...</td>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>浙商证券股份有限公司</td>\n",
       "      <td>王华君/李锋</td>\n",
       "      <td>美亚光电(002690)：2020年现金分红比例高达123%；2021年Q1高增长可期</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60715ab5a68de4a0c42408b1</td>\n",
       "      <td>公司</td>\n",
       "      <td>事件    \\r\\n    2020 年报：公司发布2020 年年报以及2021 年...</td>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>中信建投证券股份有限公司</td>\n",
       "      <td>郑勇</td>\n",
       "      <td>金禾实业(002597)：食品添加剂持续量增巩固龙头地位 资本开支大幅上行蓄力未来</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>60715ac1a68de4a0c42408b8</td>\n",
       "      <td>公司</td>\n",
       "      <td>事件    \\r\\n    公司发布2020 年年报：2020 年合计实现营业收入1...</td>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>中信建投证券股份有限公司</td>\n",
       "      <td>郑勇/邓天泽</td>\n",
       "      <td>梅花生物(600873)：以量补价业绩稳健 21年业绩可期集中释放</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60715ac1a68de4a0c42408ba</td>\n",
       "      <td>公司</td>\n",
       "      <td>公司20 年实现收入114.52 亿元，同比+29.34%；归母净利润8.38 亿元...</td>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>招商证券股份有限公司</td>\n",
       "      <td>刘荣/时文博</td>\n",
       "      <td>杭叉集团(603298)：精益管理消化原材料价格影响 尽显龙头优势</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id cate  \\\n",
       "0  60715ab0a68de4a0c42408aa   公司   \n",
       "1  60715ab2a68de4a0c42408af   公司   \n",
       "2  60715ab5a68de4a0c42408b1   公司   \n",
       "3  60715ac1a68de4a0c42408b8   公司   \n",
       "4  60715ac1a68de4a0c42408ba   公司   \n",
       "\n",
       "                                             content        date  \\\n",
       "0      事件：    \\r\\n    公司发布2021 年第一季度业绩预增公告。公司2021...  2021-04-09   \n",
       "1      2020 年营收基本与2019 年持平，现金分红比例高达123%2020 年营收约1...  2021-04-09   \n",
       "2      事件    \\r\\n    2020 年报：公司发布2020 年年报以及2021 年...  2021-04-09   \n",
       "3      事件    \\r\\n    公司发布2020 年年报：2020 年合计实现营业收入1...  2021-04-09   \n",
       "4      公司20 年实现收入114.52 亿元，同比+29.34%；归母净利润8.38 亿元...  2021-04-09   \n",
       "\n",
       "               ins      person                                        title  \n",
       "0  上海申银万国证券研究所有限公司  张雷/陈明雨/黄华栋              东方电缆(603606)：完善产业布局 海缆及海工业务高速增长  \n",
       "1       浙商证券股份有限公司      王华君/李锋  美亚光电(002690)：2020年现金分红比例高达123%；2021年Q1高增长可期  \n",
       "2     中信建投证券股份有限公司          郑勇    金禾实业(002597)：食品添加剂持续量增巩固龙头地位 资本开支大幅上行蓄力未来  \n",
       "3     中信建投证券股份有限公司      郑勇/邓天泽            梅花生物(600873)：以量补价业绩稳健 21年业绩可期集中释放  \n",
       "4       招商证券股份有限公司      刘荣/时文博            杭叉集团(603298)：精益管理消化原材料价格影响 尽显龙头优势  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/12968/Desktop/数据科学实战-stock prediction/数据/新浪公司研报.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T11:42:38.614369Z",
     "start_time": "2021-04-25T11:42:38.608351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'公司20年实现收入114.52亿元，同比+29.34%；归母净利润8.38亿元，同比+29.99%；其中，20Q4实现收入32.43亿元，+54.14%；20Q4实现归母净利润2.11亿元，增长26.92%。精益化管理及规模效应使得公司在采购原材料及零部件环节溢价能力强，淡化原材料涨价带来的成本上升风险，Q4毛利率环比微降0.94pct，优于同行业竞争对手。杭叉20年综合净利率为8.1%，与去年持平，其中Q4净利率为7.42%。受益于制造业投资回升和物流仓储需求增长，行业景气度从3月开始迅速回暖，根据工程机械协会统计销量，行业20年销量同比+32%，杭叉销量同比+49%，增速远高于行业，略高于合力（+45%），杭叉国内市占率提升4%。从收入端看，全年收入增速29.34%，低于销量增速49%，一方面由于产品价格调整，另一方面是价值量较低的电动步行式仓储叉车占比提升。从利润端看，全年综合毛利率20.35%，净利率8.1%，较19年毛利率微降1个百分点，净利率持平。人民币升值影响较大，2020年汇兑损失3597万元，扣非归母净利润7.8亿元，同比+44%。扣除2020、2019年投资收益（2020：中策投资收益1.73亿、银行理财2645万元）影响，20年（扣非净利润-投资收益）同比+45.31%，反映了叉车的利润增长情况，处于行业领先地位。在20年行业价格竞争激烈，下半年原材料涨价，人民币升值的背景下，杭叉业绩超预期，体现优质龙头企业在上游议价、成本管理和规模化效应上的优势。叉车销量与PMI指数高度相关，且PMI指数具有一定前瞻性，当前PMI连续数月保持在50的容枯线上，叠加电动平衡重式叉车替换内燃平衡重式叉车，电动步行式仓储叉车的增量空间，杭叉销量有望保持高景气。基于行业景气及杭叉自身的成本控制能力，目前估值20倍左右相对合理。风险提示：原材料成本上涨盈利能力下降的风险；2021年下半年增速放缓。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个例子\n",
    "sample = data['content'][4]\n",
    "sample = re.sub('\\xa0\\xa0\\xa0\\r\\n','',sample)\n",
    "sample = re.sub(' ','',sample)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-23T14:19:48.431Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T12:57:48.665338Z",
     "start_time": "2021-04-25T12:57:44.792894Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12968\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "C:\\Users\\12968\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\12968\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\12968\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\Users\\12968\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\12968\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\12968\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\12968\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\12968\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\12968\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    }
   ],
   "source": [
    "from nltk.tree import Tree\n",
    "import logging\n",
    "from stanfordcorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T12:58:40.361780Z",
     "start_time": "2021-04-25T12:57:52.876186Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing native server...\n",
      "INFO:root:java -Xmx4g -cp \"E:\\py\\stanford-corenlp-4.2.0\\*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000\n",
      "INFO:root:Server shell PID: 23220\n",
      "INFO:root:The server is available.\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9000\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9000 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 5342\n",
      "INFO:root:Cleanup...\n",
      "INFO:root:Killing pid: 23664, cmdline: ['java', '-Xmx4g', '-cp', 'E:\\\\py\\\\stanford-corenlp-4.2.0\\\\*', 'edu.stanford.nlp.pipeline.StanfordCoreNLPServer', '-port', '9000']\n",
      "INFO:root:Killing shell pid: 23220, cmdline: ['C:\\\\WINDOWS\\\\system32\\\\cmd.exe', '/c', 'java -Xmx4g -cp E:\\\\py\\\\stanford-corenlp-4.2.0\\\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\r\n",
      "  (IP\r\n",
      "    (NP (NR 浙江) (NN 大学))\r\n",
      "    (VP (VE 有)\r\n",
      "      (NP\r\n",
      "        (QP (CD 七)\r\n",
      "          (CLP (M 个)))\r\n",
      "        (NP (NN 校区))))\r\n",
      "    (PU 。)))\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "nlp = StanfordCoreNLP(r'E:\\py\\stanford-corenlp-4.2.0',lang='zh',quiet=False,logging_level=logging.DEBUG)\n",
    "res = nlp.parse('浙江大学有七个校区。')\n",
    "print(res)\n",
    "print(type(res))\n",
    "nlp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T08:13:43.917060Z",
     "start_time": "2021-04-24T08:13:43.899076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(ROOT\\r\\n  (IP\\r\\n    (NP (NR 浙江) (NN 大学))\\r\\n    (VP (VE 有)\\r\\n      (NP\\r\\n        (QP (CD 七)\\r\\n          (CLP (M 个)))\\r\\n        (NP (NN 校区))))\\r\\n    (PU 。)))'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T11:43:38.248241Z",
     "start_time": "2021-04-25T11:43:38.228295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(ROOT',\n",
       " '  (IP',\n",
       " '    (NP (NR 浙江) (NN 大学))',\n",
       " '    (VP (VE 有)',\n",
       " '      (NP',\n",
       " '        (QP (CD 七)',\n",
       " '          (CLP (M 个)))',\n",
       " '        (NP (NN 校区))))',\n",
       " '    (PU 。)))']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.split(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T11:45:48.799970Z",
     "start_time": "2021-04-25T11:43:41.696293Z"
    }
   },
   "outputs": [],
   "source": [
    "Tree.fromstring(res).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算节点数-计算（的个数\n",
    "result = []\n",
    "for i in res:\n",
    "    if i == '(':\n",
    "        result += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-24T07:36:27.671Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing native server...\n",
      "INFO:root:java -Xmx4g -cp \"E:\\py\\stanford-corenlp-4.2.0\\*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9003\n",
      "INFO:root:Server shell PID: 21856\n",
      "INFO:root:The server is available.\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9003\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9003 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 2399\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:51:50.637729Z",
     "start_time": "2021-04-23T14:51:50.626471Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:34:31.111303Z",
     "start_time": "2021-04-23T14:34:31.103292Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:34:37.763620Z",
     "start_time": "2021-04-23T14:34:37.755608Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:51:47.393239Z",
     "start_time": "2021-04-23T14:45:04.060267Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-c8e7505e4565>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mwith\u001B[0m \u001B[0mStanfordCoreNLP\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mr'E:/py/stanford-parser-full-2020-11-17'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlang\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'zh'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnlp\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mTree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfromstring\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnlp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\stanfordcorenlp\\corenlp.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, path_or_host, port, memory, lang, timeout, quiet, logging_level)\u001B[0m\n\u001B[0;32m    113\u001B[0m         \u001B[0mhost_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0murlparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhostname\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# OSX, not tested\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 115\u001B[1;33m         \u001B[1;32mwhile\u001B[0m \u001B[0msock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconnect_ex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhost_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mport\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    116\u001B[0m             \u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Waiting until the server is available.'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    117\u001B[0m             \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T12:33:15.981924Z",
     "start_time": "2021-04-25T12:33:15.872760Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StanfordCoreNLP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-344c0e26c79e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0msentence\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'我叫小米'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mwith\u001B[0m \u001B[0mStanfordCoreNLP\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mr'E:\\py\\stanford-corenlp-4.2.0'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlang\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'zh'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnlp\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0mTree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfromstring\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnlp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'StanfordCoreNLP' is not defined"
     ]
    }
   ],
   "source": [
    "sentence = '我叫小米'\n",
    "with StanfordCoreNLP(r'E:\\py\\stanford-corenlp-4.2.0', lang='zh') as nlp:\n",
    "    Tree.fromstring(nlp.parse(sentence)).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T12:51:39.777224Z",
     "start_time": "2021-04-25T12:50:47.778404Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing native server...\n",
      "INFO:root:java -Xmx4g -cp \"E:\\py\\stanford-corenlp-4.2.0\\*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9011\n",
      "INFO:root:Server shell PID: 22676\n",
      "INFO:root:The server is available.\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9011\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9011 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 6152\n",
      "INFO:root:Initializing native server...\n",
      "INFO:root:java -Xmx4g -cp \"E:\\py\\stanford-corenlp-4.2.0\\*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9013\n",
      "INFO:root:Server shell PID: 22920\n",
      "INFO:root:The server is available.\n",
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9013\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9013 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 500 36\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-143ec5ad4fc7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     76\u001B[0m     \u001B[0msample\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'content'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m     \u001B[0mtree\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mParseTree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msample\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 78\u001B[1;33m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'结果为'\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_less_than_16\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-10-143ec5ad4fc7>\u001B[0m in \u001B[0;36mno_less_than_16\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     55\u001B[0m         \u001B[0mnum\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0msentence\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentences\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 57\u001B[1;33m             \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     58\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mres\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[1;36m16\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m                 \u001B[0mnum\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-10-143ec5ad4fc7>\u001B[0m in \u001B[0;36mtree\u001B[1;34m(self, sentence)\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtree\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m         \u001B[0mnlp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mStanfordCoreNLP\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mr'E:\\py\\stanford-corenlp-4.2.0'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlang\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'zh'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mquiet\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogging_level\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDEBUG\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 35\u001B[1;33m         \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnlp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     36\u001B[0m         \u001B[1;31m# nlp.close()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mres\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\stanfordcorenlp\\corenlp.py\u001B[0m in \u001B[0;36mparse\u001B[1;34m(self, sentence)\u001B[0m\n\u001B[0;32m    203\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 205\u001B[1;33m         \u001B[0mr_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_request\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'pos,parse'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    206\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'parse'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ms\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mr_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'sentences'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\stanfordcorenlp\\corenlp.py\u001B[0m in \u001B[0;36m_request\u001B[1;34m(self, annotators, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m    237\u001B[0m         \u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    238\u001B[0m         \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrequests\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpost\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'Connection'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m'close'\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 239\u001B[1;33m         \u001B[0mr_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    240\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    241\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mr_dict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001B[0m in \u001B[0;36mloads\u001B[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[0;32m    346\u001B[0m             \u001B[0mparse_int\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mparse_float\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    347\u001B[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001B[1;32m--> 348\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_decoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    349\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcls\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    350\u001B[0m         \u001B[0mcls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mJSONDecoder\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001B[0m in \u001B[0;36mdecode\u001B[1;34m(self, s, _w)\u001B[0m\n\u001B[0;32m    335\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    336\u001B[0m         \"\"\"\n\u001B[1;32m--> 337\u001B[1;33m         \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraw_decode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0m_w\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    338\u001B[0m         \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_w\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    339\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001B[0m in \u001B[0;36mraw_decode\u001B[1;34m(self, s, idx)\u001B[0m\n\u001B[0;32m    353\u001B[0m             \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscan_once\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    354\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 355\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mJSONDecodeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Expecting value\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    356\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from nltk.tree import Tree\n",
    "import re\n",
    "import numpy as np\n",
    "import logging\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ParseTree:\n",
    "\n",
    "    def __init__(self, text):\n",
    "        self.text = text  # 传入的文本\n",
    "        # 定义模型\n",
    "        # self.nlp = StanfordCoreNLP(r'E:\\py\\stanford-corenlp-4.2.0', lang='zh', quiet=False, logging_level=logging.DEBUG)\n",
    "        # 分句\n",
    "        self.sentences = self.preprocess()\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        将整篇文本处理为一个列表，每个元素是文本里的句子\n",
    "        :return:返回列表\n",
    "        \"\"\"\n",
    "        sentences = []\n",
    "        self.text = re.sub(' ', '', re.sub('\\xa0\\xa0\\xa0\\r\\n', '', self.text))\n",
    "        start = 0\n",
    "        for i in range(len(self.text)):\n",
    "            if self.text[i] in ['。', '!', '；', '？', '……', '，']:\n",
    "                sentences.append(self.text[start:i + 1])\n",
    "                start = i + 1\n",
    "        return sentences\n",
    "\n",
    "    def tree(self, sentence):\n",
    "        nlp = StanfordCoreNLP(r'E:\\py\\stanford-corenlp-4.2.0', lang='zh', quiet=False, logging_level=logging.DEBUG)\n",
    "        res = nlp.parse(sentence)\n",
    "        # nlp.close()\n",
    "        return res\n",
    "\n",
    "    def sum_of_heights(self):\n",
    "        \"\"\"\n",
    "        计算整篇文本的每句话构成的语法分析树的高度之和\n",
    "        :return: 高度之和\n",
    "        \"\"\"\n",
    "        sumHeights = []\n",
    "        for sentence in self.sentences:\n",
    "            res = self.tree(sentence)  # 语法树，是个字符串\n",
    "            sum.append(len(res.split(\"\\r\\n\")))\n",
    "        return np.sum(sumHeights)\n",
    "\n",
    "    def no_less_than_16(self):\n",
    "        \"\"\"\n",
    "        计算整篇文本的高度不大于16的语法分析树的个数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num = 0\n",
    "        for sentence in self.sentences:\n",
    "            res = self.tree(sentence)\n",
    "            if len(res) >= 16:\n",
    "                num += 1\n",
    "        return num\n",
    "\n",
    "    def nodes_sum(self):\n",
    "        node_sums = []\n",
    "        for sentence in self.sentences:\n",
    "            res = self.nlp.parse(sentence)\n",
    "            result = -1  # 去除root\n",
    "            for i in res:\n",
    "                if i == '(':\n",
    "                    result += 1\n",
    "            node_sums.append(result)\n",
    "        return np.sum(node_sums)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = pd.read_csv('C:/Users/12968/Desktop/数据科学实战-stock prediction/数据/新浪公司研报.csv')\n",
    "    sample = list(data['content'])[4]\n",
    "    tree = ParseTree(sample)\n",
    "    print('结果为'+str(tree.no_less_than_16()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T15:25:09.900411Z",
     "start_time": "2021-04-25T15:25:06.702931Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing native server...\n",
      "INFO:root:java -Xmx4g -cp \"E:\\py\\stanford-corenlp-4.2.0\\*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9008\n",
      "INFO:root:Server shell PID: 19624\n",
      "INFO:root:The server is available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------sample--------------\n",
      "    事件    \r\n",
      "    公司发布2020 年年报：2020 年合计实现营业收入170.50 亿元，实现同比增长17.15%，实现归母净利9.82 亿元，同比减少0.67%。    \r\n",
      "    对应Q4 单季净利润1.63 亿元，环比下降11%，同比增长22%。    \r\n",
      "    简评    \r\n",
      "    苏、赖氨酸价格改善，产品产销明显增加，量价齐升支撑业绩产品价格方面，味精、苏氨酸、赖氨酸在2020 年平均价格分别为7430、8386、7502，分别同比-722、+1033、+983 元/吨，整体有增有减，但原料玉米价格在2020 年仍有明显涨价，综合来看公司产品毛利率仍然有所下行。    \r\n",
      "    产品产销量方面，白城基地40 万吨赖氨酸19 年投产、25 万吨味精20 年投产，为公司20 年贡献产能增量；同时，公司克服疫情影响，生产经营基本稳定。主要产品产销量因此均有明显增长，动物营养氨基酸产品（苏、赖氨酸等）销量增加16.43%，食品味觉形状优化产品（味精等）销量增加9.57%。以量补价，公司因此实现2020 年净利基本稳定。    \r\n",
      "    费用率方面，公司全年销售、管理、财务费用率分别为2.16%、3.85%、0.83%，同比分别-5.87、-0.28、-1.03pct，其中销售费用率下降系会计政策变更，运费调整至营业成本项目，对公司利润无影响。    \r\n",
      "    利润分配方面，公司预计分派现金红利9.3 亿元，占2020 年全年归母净利的94.70%，保持了一贯的高股息政策，以当前市值计算，股息率也达到4.95%。    \r\n",
      "    苏赖氨酸Q1 大幅提价，21 年公司业绩有望集中释放味精及氨基酸，从长期逻辑看，行业竞争仍将从无序变为有序，行业价格中枢有望稳步提高。2021 年以来，受到需求回暖、玉米涨价支撑成本、企业协同等因素驱动，连续上调氨基酸产品报价，赖氨酸、苏氨酸市场价连续上行、价差也大幅走扩。Q1，苏氨酸、赖氨酸平均价差分别为8310、7485 元/吨，分别较2020 年大幅提升6452、4572 元/吨，公司产品实际交易价涨幅虽未必达到报价涨幅，但Q1 起业绩仍有望集中释放。    \r\n",
      "    另一方面，内蒙能耗新政出台以来，当地味精、氨基酸有停止报价，后续如有限产或将加剧供应紧张。味精的内蒙古产能占比达到44%，赖氨酸方面，伊品赤峰工厂产能20 万吨，占比6.2%，苏氨酸内蒙古占比52%左右，根据博亚和讯等，部分味精、氨基酸企业已经开始出现停报价格，有降低负荷情况。    \r\n",
      "    行业产能高度集中，公司规模经济和成本优势，龙头优势愈发凸显公司以味精和动物饲料氨基酸为双主业，产品方面，公司赖氨酸产能为全球第一，味精产能市场占有率为20%，仅次于国内龙头阜丰集团，但是如果以产量计算，CR3（阜丰、梅花、伊品）市占率已经达到90%以上。公司以鲜味剂、饲料级氨基酸、工业级与石油级黄原胶等多个优势产品为核心的业务结构，使得公司拥有氨基酸生产领域最全的产品谱系。多产品均衡发展有利于降低单一产品价格波动或行业周期带来的不利影响，较同行业企业拥有更加的规模经济效应和产品协同效应；此外，公司现有三个生产基地分别位于内蒙古通辽、新疆五家渠和吉林白城，均系国内动力煤和玉米的主要产地，赋予公司领先全行业的成本优势（味精毛利率高于阜丰集团和宁夏伊品）。    \r\n",
      "    预测公司2021、2022、2023 年归母净利分别为16.29、18.05、20.86 亿元，对应PE 分别为11X、10X、9X，维持“增持”评级。    \r\n",
      "    风险提示    \r\n",
      "    公司在内蒙古通辽有生产基地，存在限产风险；氨基酸价格大幅波动\n",
      "-----------------------------------------\n",
      "-------------------sentences--------------\n",
      "['事件公司发布2020年年报：', '2020年合计实现营业收入170.50亿元，', '实现同比增长17.15%，', '实现归母净利9.82亿元，', '同比减少0.67%。', '对应Q4单季净利润1.63亿元，', '环比下降11%，', '同比增长22%。', '简评苏、赖氨酸价格改善，', '产品产销明显增加，', '量价齐升支撑业绩产品价格方面，', '味精、苏氨酸、赖氨酸在2020年平均价格分别为7430、8386、7502，', '分别同比-722、+1033、+983元/吨，', '整体有增有减，', '但原料玉米价格在2020年仍有明显涨价，', '综合来看公司产品毛利率仍然有所下行。', '产品产销量方面，', '白城基地40万吨赖氨酸19年投产、25万吨味精20年投产，', '为公司20年贡献产能增量；', '同时，', '公司克服疫情影响，', '生产经营基本稳定。', '主要产品产销量因此均有明显增长，', '动物营养氨基酸产品（苏、赖氨酸等）销量增加16.43%，', '食品味觉形状优化产品（味精等）销量增加9.57%。', '以量补价，', '公司因此实现2020年净利基本稳定。', '费用率方面，', '公司全年销售、管理、财务费用率分别为2.16%、3.85%、0.83%，', '同比分别-5.87、-0.28、-1.03pct，', '其中销售费用率下降系会计政策变更，', '运费调整至营业成本项目，', '对公司利润无影响。', '利润分配方面，', '公司预计分派现金红利9.3亿元，', '占2020年全年归母净利的94.70%，', '保持了一贯的高股息政策，', '以当前市值计算，', '股息率也达到4.95%。', '苏赖氨酸Q1大幅提价，', '21年公司业绩有望集中释放味精及氨基酸，', '从长期逻辑看，', '行业竞争仍将从无序变为有序，', '行业价格中枢有望稳步提高。', '2021年以来，', '受到需求回暖、玉米涨价支撑成本、企业协同等因素驱动，', '连续上调氨基酸产品报价，', '赖氨酸、苏氨酸市场价连续上行、价差也大幅走扩。', 'Q1，', '苏氨酸、赖氨酸平均价差分别为8310、7485元/吨，', '分别较2020年大幅提升6452、4572元/吨，', '公司产品实际交易价涨幅虽未必达到报价涨幅，', '但Q1起业绩仍有望集中释放。', '另一方面，', '内蒙能耗新政出台以来，', '当地味精、氨基酸有停止报价，', '后续如有限产或将加剧供应紧张。', '味精的内蒙古产能占比达到44%，', '赖氨酸方面，', '伊品赤峰工厂产能20万吨，', '占比6.2%，', '苏氨酸内蒙古占比52%左右，', '根据博亚和讯等，', '部分味精、氨基酸企业已经开始出现停报价格，', '有降低负荷情况。', '行业产能高度集中，', '公司规模经济和成本优势，', '龙头优势愈发凸显公司以味精和动物饲料氨基酸为双主业，', '产品方面，', '公司赖氨酸产能为全球第一，', '味精产能市场占有率为20%，', '仅次于国内龙头阜丰集团，', '但是如果以产量计算，', 'CR3（阜丰、梅花、伊品）市占率已经达到90%以上。', '公司以鲜味剂、饲料级氨基酸、工业级与石油级黄原胶等多个优势产品为核心的业务结构，', '使得公司拥有氨基酸生产领域最全的产品谱系。', '多产品均衡发展有利于降低单一产品价格波动或行业周期带来的不利影响，', '较同行业企业拥有更加的规模经济效应和产品协同效应；', '此外，', '公司现有三个生产基地分别位于内蒙古通辽、新疆五家渠和吉林白城，', '均系国内动力煤和玉米的主要产地，', '赋予公司领先全行业的成本优势（味精毛利率高于阜丰集团和宁夏伊品）。', '预测公司2021、2022、2023年归母净利分别为16.29、18.05、20.86亿元，', '对应PE分别为11X、10X、9X，', '维持“增持”评级。', '风险提示公司在内蒙古通辽有生产基地，', '存在限产风险；']\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from nltk.tree import Tree\n",
    "import logging\n",
    "import pandas as pd\n",
    "import re\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "data = pd.read_csv('C:/Users/12968/Desktop/数据科学实战-stock prediction/数据/新浪公司研报.csv')\n",
    "nlp = StanfordCoreNLP(r'E:\\py\\stanford-corenlp-4.2.0',lang='zh',quiet=False,logging_level=logging.DEBUG)\n",
    "sample = list(data['content'])[3:4][0]\n",
    "# for sample in samples:\n",
    "sentences = []\n",
    "text = re.sub(' ', '', re.sub('\\xa0\\xa0\\xa0\\r\\n', '', sample))\n",
    "print('-------------------sample--------------')\n",
    "print(sample)\n",
    "print('-----------------------------------------')\n",
    "start = 0\n",
    "for i in range(len(text)):\n",
    "    if text[i] in ['。', '!', '；', '？', '……', '：']:\n",
    "        sentences.append(text[start:i + 1])\n",
    "        start = i + 1\n",
    "print('-------------------sentences--------------')\n",
    "print(sentences)\n",
    "print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T15:26:55.645250Z",
     "start_time": "2021-04-25T15:25:31.537756Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9008\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9008 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 4712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\r\n",
      "  (IP\r\n",
      "    (NP (NN 事件) (NN 公司))\r\n",
      "    (VP (VV 发布)\r\n",
      "      (NP\r\n",
      "        (NP (NT 2020年))\r\n",
      "        (NP (NN 年报))\r\n",
      "        (PU ：)))))\n"
     ]
    }
   ],
   "source": [
    "sentence = sentences[0]\n",
    "print(sentence)\n",
    "res = nlp.parse(sentence)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T15:27:50.464281Z",
     "start_time": "2021-04-25T15:27:50.402447Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9008\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9008 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 6233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020年合计实现营业收入170.50亿元，\n",
      "(ROOT\r\n",
      "  (IP\r\n",
      "    (NP (NT 2020年))\r\n",
      "    (VP\r\n",
      "      (ADVP (AD 合计))\r\n",
      "      (VP (VV 实现)\r\n",
      "        (NP (NN 营业) (NN 收入))\r\n",
      "        (QP (CD 170.50亿)\r\n",
      "          (CLP (M 元)))))\r\n",
      "    (PU ，)))\n"
     ]
    }
   ],
   "source": [
    "sentence = sentences[1]\n",
    "print(sentence)\n",
    "res = nlp.parse(sentence)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T15:27:52.595010Z",
     "start_time": "2021-04-25T15:27:52.555082Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9008\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9008 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 500 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实现同比增长17.15%，\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-a59c999f99c5>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0msentence\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msentences\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnlp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mres\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\stanfordcorenlp\\corenlp.py\u001B[0m in \u001B[0;36mparse\u001B[1;34m(self, sentence)\u001B[0m\n\u001B[0;32m    203\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 205\u001B[1;33m         \u001B[0mr_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_request\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'pos,parse'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    206\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'parse'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ms\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mr_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'sentences'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\stanfordcorenlp\\corenlp.py\u001B[0m in \u001B[0;36m_request\u001B[1;34m(self, annotators, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m    237\u001B[0m         \u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    238\u001B[0m         \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrequests\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpost\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'Connection'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m'close'\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 239\u001B[1;33m         \u001B[0mr_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    240\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    241\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mr_dict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001B[0m in \u001B[0;36mloads\u001B[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[0;32m    346\u001B[0m             \u001B[0mparse_int\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mparse_float\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    347\u001B[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001B[1;32m--> 348\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_decoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    349\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcls\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    350\u001B[0m         \u001B[0mcls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mJSONDecoder\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001B[0m in \u001B[0;36mdecode\u001B[1;34m(self, s, _w)\u001B[0m\n\u001B[0;32m    335\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    336\u001B[0m         \"\"\"\n\u001B[1;32m--> 337\u001B[1;33m         \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraw_decode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0m_w\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    338\u001B[0m         \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_w\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    339\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001B[0m in \u001B[0;36mraw_decode\u001B[1;34m(self, s, idx)\u001B[0m\n\u001B[0;32m    353\u001B[0m             \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscan_once\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    354\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 355\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mJSONDecodeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Expecting value\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    356\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "sentence = sentences[2]\n",
    "print(sentence)\n",
    "res = nlp.parse(sentence)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T15:27:56.823099Z",
     "start_time": "2021-04-25T15:27:56.776249Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9008\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9008 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 200 4684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实现归母净利9.82亿元，\n",
      "(ROOT\r\n",
      "  (IP\r\n",
      "    (VP (VV 实现)\r\n",
      "      (NP (NN 归母) (NN 净利))\r\n",
      "      (QP (CD 9.82亿)\r\n",
      "        (CLP (M 元))))\r\n",
      "    (PU ，)))\n"
     ]
    }
   ],
   "source": [
    "sentence = sentences[3]\n",
    "print(sentence)\n",
    "res = nlp.parse(sentence)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T15:27:58.518650Z",
     "start_time": "2021-04-25T15:27:58.481755Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'properties': \"{'annotators': 'pos,parse', 'outputFormat': 'json'}\", 'pipelineLanguage': 'zh'}\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:9008\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:9008 \"POST /?properties=%7B%27annotators%27%3A+%27pos%2Cparse%27%2C+%27outputFormat%27%3A+%27json%27%7D&pipelineLanguage=zh HTTP/1.1\" 500 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "同比减少0.67%。\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-89c23ae10f10>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0msentence\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msentences\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnlp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mres\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\stanfordcorenlp\\corenlp.py\u001B[0m in \u001B[0;36mparse\u001B[1;34m(self, sentence)\u001B[0m\n\u001B[0;32m    203\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 205\u001B[1;33m         \u001B[0mr_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_request\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'pos,parse'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    206\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'parse'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ms\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mr_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'sentences'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\stanfordcorenlp\\corenlp.py\u001B[0m in \u001B[0;36m_request\u001B[1;34m(self, annotators, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m    237\u001B[0m         \u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    238\u001B[0m         \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrequests\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpost\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'Connection'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m'close'\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 239\u001B[1;33m         \u001B[0mr_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    240\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    241\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mr_dict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001B[0m in \u001B[0;36mloads\u001B[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[0;32m    346\u001B[0m             \u001B[0mparse_int\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mparse_float\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    347\u001B[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001B[1;32m--> 348\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_decoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    349\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcls\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    350\u001B[0m         \u001B[0mcls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mJSONDecoder\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001B[0m in \u001B[0;36mdecode\u001B[1;34m(self, s, _w)\u001B[0m\n\u001B[0;32m    335\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    336\u001B[0m         \"\"\"\n\u001B[1;32m--> 337\u001B[1;33m         \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraw_decode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0m_w\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    338\u001B[0m         \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_w\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    339\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001B[0m in \u001B[0;36mraw_decode\u001B[1;34m(self, s, idx)\u001B[0m\n\u001B[0;32m    353\u001B[0m             \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscan_once\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    354\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 355\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mJSONDecodeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Expecting value\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    356\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "sentence = sentences[4]\n",
    "print(sentence)\n",
    "res = nlp.parse(sentence)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T15:45:53.413357Z",
     "start_time": "2021-04-25T15:45:53.082242Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-5b78a5b288ce>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnlp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'受到需求回暖、玉米涨价支撑成本、企业协同等因素驱动,连续上调氨基酸产品报价'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mres\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "res = nlp.parse('受到需求回暖、玉米涨价支撑成本、企业协同等因素驱动,连续上调氨基酸产品报价')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tree import Tree\n",
    "import logging\n",
    "import pandas as pd\n",
    "import re\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "data = pd.read_csv('C:/Users/12968/Desktop/数据科学实战-stock prediction/数据/新浪公司研报.csv')\n",
    "nlp = StanfordCoreNLP(r'E:\\py\\stanford-corenlp-4.2.0',lang='zh',quiet=False,logging_level=logging.DEBUG)\n",
    "sample = list(data['content'])[3:4][0]\n",
    "sentences = []\n",
    "text = re.sub(' ', '', re.sub('\\xa0\\xa0\\xa0\\r\\n', '', sample))\n",
    "start = 0\n",
    "for i in range(len(text)):\n",
    "    if text[i] in ['。', '!', '；', '？', '……', '：']:\n",
    "        sentences.append(text[start:i + 1])\n",
    "        start = i + 1\n",
    "\n",
    "# 给定sentences\n",
    "\n",
    "for sentence in sentences:\n",
    "    num = 0\n",
    "    res = nlp.parse(sentence)\n",
    "    for i in res:\n",
    "        if 'NP' in i:\n",
    "            num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}